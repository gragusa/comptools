[
  {
    "objectID": "junk/index.html",
    "href": "junk/index.html",
    "title": "Computational Tools for Macroeconometrics (AAF2351)",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, University of Rome\n   Department of Economics and Law\n   Viale del Castro Laurenziano, 9\n   giuseppe.ragusa at uniroma1 dot it\n   Office Hour:\n\n\n\n\n\n   Friday\n   19 february, 2024 - 30 may 2024\n   12:00-14:00\n   Ecodir"
  },
  {
    "objectID": "junk/index.html#description",
    "href": "junk/index.html#description",
    "title": "Computational Tools for Macroeconometrics (AAF2351)",
    "section": "Description",
    "text": "Description\nComputational Tools for Macroeconometrics (AAF2351) covers the computational aspects of time series. It begins with an overview of the computational challenges inherent in macroeconomic data analysis and the pivotal role of software tools, with a particular focus on Python, Julia and R. The syllabus covers a broad range of topics starting gong from forecasting to nonlinear optimization and simulations.\nThe course is structured as an interactive lab, emphasizing a hands-on learning approach through practical assignments. In this lab environment, students are expected to learn by doing, applying the theoretical knowledge acquired in lectures to real-world data and scenarios."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Tools for Macroeconometrics (AAF2351)",
    "section": "",
    "text": "Prof. Giuseppe Ragusa\n   Sapienza, University of Rome\n   Department of Economics and Law\n   Viale del Castro Laurenziano, 9\n   giuseppe.ragusa at uniroma1 dot it\n   Office Hour:\n\n\n\n\n\n   Friday\n   19 february, 2024 - 30 may 2024\n   12:00-14:00\n   Ecodir"
  },
  {
    "objectID": "index.html#description",
    "href": "index.html#description",
    "title": "Computational Tools for Macroeconometrics (AAF2351)",
    "section": "Description",
    "text": "Description\nComputational Tools for Macroeconometrics (AAF2351) covers the computational aspects of time series. It begins with an overview of the computational challenges inherent in macroeconomic data analysis and the pivotal role of software tools, with a particular focus on Python, Julia and R. The syllabus covers a broad range of topics starting gong from forecasting to nonlinear optimization and simulations.\nThe course is structured as an interactive lab, emphasizing a hands-on learning approach through practical assignments. In this lab environment, students are expected to learn by doing, applying the theoretical knowledge acquired in lectures to real-world data and scenarios."
  },
  {
    "objectID": "comptools_ass1.html",
    "href": "comptools_ass1.html",
    "title": "Computational Tools for Macroeconometrics",
    "section": "",
    "text": "This assignment introduces students to practical and theoretical aspects of macroeconometrics, focusing on forecasting using the FRED-MD dataset. Students will learn to handle macroeconomic data, perform necessary transformations, apply univariate models to predict key economic indicators and to evaluate these forecasts."
  },
  {
    "objectID": "comptools_ass1.html#introduction",
    "href": "comptools_ass1.html#introduction",
    "title": "Computational Tools for Macroeconometrics",
    "section": "",
    "text": "This assignment introduces students to practical and theoretical aspects of macroeconometrics, focusing on forecasting using the FRED-MD dataset. Students will learn to handle macroeconomic data, perform necessary transformations, apply univariate models to predict key economic indicators and to evaluate these forecasts."
  },
  {
    "objectID": "comptools_ass1.html#the-fred-md-dataset",
    "href": "comptools_ass1.html#the-fred-md-dataset",
    "title": "Computational Tools for Macroeconometrics",
    "section": "The FRED-MD dataset",
    "text": "The FRED-MD dataset\nThe FRED-MD dataset is a comprehensive monthly database for macroeconomic research compiled by the Federal Reserve Bank of St. Louis. It features a wide array of economic indicators. The list of economic indicators can be obtained from the paper accompanying the data pdf.\nThe data can be downloaded here. The page contains all the different vintages of the data.\nLet us start to download the current.csv file:\n\nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('~/Downloads/current.csv')\n\n# Clean the DataFrame by removing the row with transformation codes\ndf_cleaned = df.drop(index=0)\ndf_cleaned.reset_index(drop=True, inplace=True)\ndf_cleaned['sasdate'] = pd.to_datetime(df_cleaned['sasdate'], format='%m/%d/%Y')\ndf_cleaned\n\n\n\n\n\n\n\n\n\nsasdate\nRPI\nW875RX1\nDPCERA3M086SBEA\nCMRMTSPLx\nRETAILx\nINDPRO\nIPFPNSS\nIPFINAL\nIPCONGD\n...\nDNDGRG3M086SBEA\nDSERRG3M086SBEA\nCES0600000008\nCES2000000008\nCES3000000008\nUMCSENTx\nDTCOLNVHFNM\nDTCTHFNM\nINVEST\nVIXCLSx\n\n\n\n\n0\n1959-01-01\n2583.560\n2426.0\n15.188\n2.766768e+05\n18235.77392\n21.9665\n23.3891\n22.2688\n31.7011\n...\n18.294\n10.152\n2.13\n2.45\n2.04\nNaN\n6476.00\n12298.00\n84.2043\nNaN\n\n\n1\n1959-02-01\n2593.596\n2434.8\n15.346\n2.787140e+05\n18369.56308\n22.3966\n23.7048\n22.4617\n31.9337\n...\n18.302\n10.167\n2.14\n2.46\n2.05\nNaN\n6476.00\n12298.00\n83.5280\nNaN\n\n\n2\n1959-03-01\n2610.396\n2452.7\n15.491\n2.777753e+05\n18523.05762\n22.7193\n23.8483\n22.5719\n31.9337\n...\n18.289\n10.185\n2.15\n2.45\n2.07\nNaN\n6508.00\n12349.00\n81.6405\nNaN\n\n\n3\n1959-04-01\n2627.446\n2470.0\n15.435\n2.833627e+05\n18534.46600\n23.2032\n24.1927\n22.9026\n32.4374\n...\n18.300\n10.221\n2.16\n2.47\n2.08\nNaN\n6620.00\n12484.00\n81.8099\nNaN\n\n\n4\n1959-05-01\n2642.720\n2486.4\n15.622\n2.853072e+05\n18679.66354\n23.5528\n24.3936\n23.1231\n32.5925\n...\n18.280\n10.238\n2.17\n2.48\n2.08\n95.3\n6753.00\n12646.00\n80.7315\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n776\n2023-09-01\n19111.748\n15741.9\n116.594\n1.507530e+06\n705304.00000\n103.2096\n101.0935\n101.3665\n102.1034\n...\n120.395\n123.976\n29.90\n34.55\n26.62\n67.9\n508808.61\n913938.95\n5074.6108\n15.0424\n\n\n777\n2023-10-01\n19145.402\n15784.6\n116.663\n1.505477e+06\n703528.00000\n102.3722\n100.5292\n100.5527\n101.1664\n...\n120.040\n124.228\n29.97\n34.67\n26.65\n63.8\n513229.64\n918210.64\n5015.5456\n19.0462\n\n\n778\n2023-11-01\n19213.108\n15859.9\n117.127\n1.514733e+06\n703336.00000\n102.6710\n100.9362\n101.2159\n101.8557\n...\n119.325\n124.551\n30.26\n34.96\n26.89\n61.3\n517434.30\n922552.40\n4999.7208\n13.8563\n\n\n779\n2023-12-01\n19251.946\n15899.0\n117.773\n1.530296e+06\n706180.00000\n102.6715\n100.8332\n101.2843\n101.9884\n...\n119.193\n124.917\n30.45\n35.01\n27.14\n69.7\n522366.13\n928336.14\n5077.4222\n12.6960\n\n\n780\n2024-01-01\n19377.558\n15948.8\n117.639\nNaN\n700291.00000\n102.5739\n100.9984\n101.7258\n102.6235\n...\n118.745\n125.662\n30.56\n35.21\n27.22\nNaN\nNaN\nNaN\n5105.3504\n13.3453\n\n\n\n\n781 rows × 128 columns\n\n\n\n\n\n# Extract transformation codes\ntransformation_codes = df.iloc[0, 1:].to_frame().reset_index()\ntransformation_codes.columns = ['Series', 'Transformation_Code']\n\nThe transformation codes map variables to the transformations we must apply to each variable to render them (approximately) stationary. The data frame transformation_codes has the variable’s name (Series) and its transformation (Transformation_Code). There are six possible transformations (\\(x_t\\) denotes the variable to which the transformation is to be applied):\n\ntransformation_code=1: no trasformation\ntransformation_code=2: \\(\\Delta x_t\\)\ntransformation_code=3: \\(\\Delta^2 x_t\\)\ntransformation_code=4: \\(log(x_t)\\)\ntransformation_code=5: \\(\\Delta log(x_t)\\)\ntransformation_code=6: \\(\\Delta^2 log(x_t)\\)\ntransformation_code=7: \\(\\Delta (x_t/x_{t-1} - 1)\\)\n\nWe can apply these transformations using the following code:\n\nimport numpy as np\n\n# Function to apply transformations based on the transformation code\ndef apply_transformation(series, code):\n    if code == 1:\n        # No transformation\n        return series\n    elif code == 2:\n        # First difference\n        return series.diff()\n    elif code == 3:\n        # Second difference\n        return series.diff().diff()\n    elif code == 4:\n        # Log\n        return np.log(series)\n    elif code == 5:\n        # First difference of log\n        return np.log(series).diff()\n    elif code == 6:\n        # Second difference of log\n        return np.log(series).diff().diff()\n    elif code == 7:\n        # Delta (x_t/x_{t-1} - 1)\n        return series.pct_change()\n    else:\n        raise ValueError(\"Invalid transformation code\")\n\n# Applying the transformations to each column in df_cleaned based on transformation_codes\nfor series_name, code in transformation_codes.values:\n    df_cleaned[series_name] = apply_transformation(df_cleaned[series_name].astype(float), float(code))\n\n\n1df_cleaned = df_cleaned[2:]\n2df_cleaned.reset_index(drop=True, inplace=True)\ndf_cleaned.head()\n\n\n1\n\nSince some transformations induce missing values, we drop the first two observations of the dataset\n\n2\n\nWe reset the index so that the first observation of the dataset has index 0\n\n\n\n\n\n\n\n\n\n\n\n\nsasdate\nRPI\nW875RX1\nDPCERA3M086SBEA\nCMRMTSPLx\nRETAILx\nINDPRO\nIPFPNSS\nIPFINAL\nIPCONGD\n...\nDNDGRG3M086SBEA\nDSERRG3M086SBEA\nCES0600000008\nCES2000000008\nCES3000000008\nUMCSENTx\nDTCOLNVHFNM\nDTCTHFNM\nINVEST\nVIXCLSx\n\n\n\n\n0\n1959-03-01\n0.006457\n0.007325\n0.009404\n-0.003374\n0.008321\n0.014306\n0.006035\n0.004894\n0.000000\n...\n-0.001148\n0.000292\n-0.000022\n-0.008147\n0.004819\nNaN\n0.004929\n0.004138\n-0.014792\nNaN\n\n\n1\n1959-04-01\n0.006510\n0.007029\n-0.003622\n0.019915\n0.000616\n0.021075\n0.014338\n0.014545\n0.015650\n...\n0.001312\n0.001760\n-0.000022\n0.012203\n-0.004890\nNaN\n0.012134\n0.006734\n0.024929\nNaN\n\n\n2\n1959-05-01\n0.005796\n0.006618\n0.012043\n0.006839\n0.007803\n0.014955\n0.008270\n0.009582\n0.004770\n...\n-0.001695\n-0.001867\n-0.000021\n-0.004090\n-0.004819\nNaN\n0.002828\n0.002020\n-0.015342\nNaN\n\n\n3\n1959-06-01\n0.003068\n0.003012\n0.003642\n-0.000097\n0.009064\n0.001141\n0.007034\n0.007128\n-0.004767\n...\n0.003334\n0.001946\n-0.004619\n0.003992\n0.004796\nNaN\n0.009726\n0.009007\n-0.012252\nNaN\n\n\n4\n1959-07-01\n-0.000580\n-0.000762\n-0.003386\n0.012155\n-0.000330\n-0.024240\n0.001168\n0.008249\n0.013054\n...\n-0.001204\n-0.000013\n0.000000\n-0.004040\n-0.004796\nNaN\n-0.004631\n-0.001000\n0.029341\nNaN\n\n\n\n\n5 rows × 128 columns\n\n\n\n\n\n1import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n2series_to_plot = ['INDPRO', 'CPIAUCSL', 'TB3MS']\nseries_names = ['Industrial Production',\n                'Inflation (CPI)',\n                '3-month Treasury Bill rate']\n\n\n# Create a figure and a grid of subplots\n3fig, axs = plt.subplots(len(series_to_plot), 1, figsize=(8, 15))\n\n# Iterate over the selected series and plot each one\nfor ax, series_name, plot_title in zip(axs, series_to_plot, series_names):\n4    if series_name in df_cleaned.columns:\n5        dates = pd.to_datetime(df_cleaned['sasdate'], format='%m/%d/%Y')\n6        ax.plot(dates, df_cleaned[series_name], label=plot_title)\n7        ax.xaxis.set_major_locator(mdates.YearLocator(base=5))\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n8        ax.set_title(plot_title)\n9        ax.set_xlabel('Year')\n        ax.set_ylabel('Transformed Value')\n10        ax.legend(loc='upper left')\n11        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n    else:\n        ax.set_visible(False)  # Hide plots for which the data is not available\n\n12plt.tight_layout()\n13plt.show()\n\n\n1\n\nWe use library matplotlib to plot\n\n2\n\nWe consider three series (INDPRO, CPIAUCSL, TB3MS) and assign them human-readable names (“Industrial Production”, “Inflation (CPI)”, “3-month Treasury Bill rate.”).\n\n3\n\nWe create a figure with three (len(series_to_plot)) subplots arranged vertically. The figure size is 8x15 inches.\n\n4\n\nWe check if the series exists in each series df_cleaned DataFrame columns.\n\n5\n\nWe convert the sasdate column to datetime format (not necessary, since sasdate was converter earlier)\n\n6\n\nWe plot each series against the sasdate on the corresponding subplot, labeling the plot with its human-readable name.\n\n7\n\nWe format the x-axis to display ticks and label the x-axis with dates taken every five years.\n\n8\n\nEach subplot is titled with the name of the economic indicator.\n\n9\n\nWe label the x-axis “Year,” and the y-axis “Transformed Value,” to indicate that the data was transformed before plotting.\n\n10\n\nA legend is added to the upper left of each subplot for clarity.\n\n11\n\nWe rotate the x-axis labels by 45 degrees to prevent overlap and improve legibility.\n\n12\n\nplt.tight_layout() automatically adjusts subplot parameters to give specified padding and avoid overlap.\n\n13\n\nplt.show() displays the figure with its subplots."
  },
  {
    "objectID": "comptools_ass1.html#forecasting-in-time-series",
    "href": "comptools_ass1.html#forecasting-in-time-series",
    "title": "Computational Tools for Macroeconometrics",
    "section": "Forecasting in Time Series",
    "text": "Forecasting in Time Series\nForecasting in time series analysis involves using historical data to predict future values. The objective is to model the conditional expectation of a time series based on past observations.\n\nDirect Forecasts\nDirect forecasting involves modeling the target variable directly at the desired forecast horizon. Unlike iterative approaches, which forecast one step ahead and then use those forecasts as inputs for subsequent steps, direct forecasting directly models the relationship between past observations and future value.\n\n\nARX Models\nAutoregressive Moving with predictors (ARX) models are a class of univariate time series models that extend ARMA models by incorporating exogenous (independent) variables. These models are formulated as follows:\n\\[\n\\begin{aligned}\nY_{t+h} &=  \\alpha + \\phi_0 Y_t + \\phi_1 Y_{t-1} + \\dots + \\phi_p Y_{t-p} + \\theta_{0,1} X_{t,1} + \\theta_{1,1} X_{t-1,1} + \\dots + \\theta_{p,1} X_{t-p,1} + \\dots + \\theta_{0,k} X_{t,k} + \\dots + \\theta_{p,k} X_{t-p,k} + u_{t+h}\\\\\n        &=  \\alpha + \\sum_{i=0}^p \\phi_i Y_{t-i} + \\sum_{j=1}^k\\sum_{s=0}^p \\theta_{s,j} X_{t-s,j} + \\epsilon_{t+h}\n\\end{aligned}\n\\tag{1}\\]\n\n\\(Y_{t+h}\\): The target variable at time \\(t+h\\).\n\\(X_{t,j}\\): Predictors (variable \\(j=1,\\ldots,k\\) at time \\(t\\)).\n\\(p\\) number of lags of the target and the predictors.1\n\\(\\phi_i\\), \\(i=0,\\dots,p\\), and \\(\\theta_{j,s}\\), \\(j=1,\\dots,k\\), \\(s=1,\\ldots,r\\): Parameters of the model.\n\\(\\epsilon_{t+h}\\): error term.\n\nFor instance, to predict Industrial Prediction using as predictor inflation and the 3-month t-bill, the target variable is INDPRO, and the predictors are CPIAUSL and TB3MS. Notice that the target and the predictors are the transformed variables. Thus, if we use INDPRO as the target, we are predicting the log-difference of industrial production, which is a good approximation for its month-to-month percentage change.\nBy convention, the data ranges from \\(t=1,\\ldots,T\\), where \\(T\\) is the last period, we have data (for the df_cleaned dataset, \\(T\\) corresponds to January 2024).\n\n\nForecasting with ARX\nSuppose that we know the parameters of the model for the moment. To obtain a forecast for \\(Y_{T+h}\\), the \\(h\\)-step ahead forecast, we calculate \\[\n\\begin{aligned}\n\\hat{Y}_{T+h} &=  \\alpha + \\phi_0 Y_T + \\phi_1 Y_{T-1} + \\dots + \\phi_p Y_{T-p} \\\\\n                  &\\,\\,\\quad \\quad + \\theta_{0,1} X_{T,1} + \\theta_{1,1} X_{T-1,1} + \\dots + \\theta_{p,1} X_{T-p,1} \\\\\n                  &\\,\\,\\quad \\quad + \\dots + \\theta_{0,k} X_{T,k} + \\dots + \\theta_{p,k} X_{T-p,k}\\\\\n        &=  \\alpha + \\sum_{i=0}^p \\phi_i Y_{T-i} + \\sum_{j=1}^k\\sum_{s=0}^p \\theta_{s,j} X_{T-s,j}\n\\end{aligned}\n\\]\nWhile this is conceptually easy, implementing the steps needed to calculate the forecast is insidious, and care must be taken to ensure we are calculating the correct forecast.\nTo start, it is convenient to rewrite the model in Equation 1 as a linear model \\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{u},\n\\] where \\(\\boldsymbol{\\beta}\\) is the vector (of size \\(1+(1+p)(1+k)\\)) \\[\n\\boldsymbol{\\beta}=\\begin{pmatrix}\\alpha\\\\\n\\phi_{0}\\\\\n\\vdots\\\\\n\\phi_{p}\\\\\n\\theta_{0,1}\\\\\n\\vdots\\\\\n\\theta_{p,1}\\\\\n\\vdots\\\\\n\\theta_{1,k}\\\\\n\\vdots\\\\\n\\theta_{p,k}\n\\end{pmatrix},\n\\] \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) are respectively given by \\[\n\\mathbf{y} = \\begin{pmatrix}\ny_{p+h+1}  \\\\\ny_{p+h+2}\\\\\n\\vdots \\\\\ny_{T}\n\\end{pmatrix}\n\\] and \\[\n\\mathbf{X} = \\begin{pmatrix}1 & Y_{p+1} & Y_{p} & \\cdots & Y_{1} & X_{p+1,1} & X_{p,1} & \\cdots & X_{1,1} & X_{p+1,k} & X_{p,k} & \\cdots & X_{1,k}\\\\\n\\vdots & \\vdots & \\vdots &  & \\vdots & \\vdots & \\vdots &  & \\vdots & \\vdots & \\vdots &  & \\vdots\\\\\n1 & Y_{T-h-1} & Y_{T-h-2} & \\cdots & Y_{T-h-p-1} & X_{T-h-1,1} & X_{T-h-2,1} & \\cdots & X_{T-h-p-1,1} & X_{T-h-1,k} & X_{T-h-2,k} & \\cdots & X_{T-h-p-1,k}\\\\\n1 & Y_{T-h} & Y_{T-h-1} & \\cdots & Y_{T-h-p} & X_{T-h,1} & X_{T-h-1,1} & \\cdots & X_{T-h-p,1} & X_{T-h,k} & X_{T-h-1,k} &  & X_{T-h-p,k}\n\\end{pmatrix}.\n\\] The size of \\(\\mathbf{X}\\) is \\((T-p-h)\\times 1+(1+k)(1+p)\\) and that of \\(\\mathbf{y}\\) is \\(T-h-p\\).\nThe matrix \\(\\mathbf{X}\\) can be obtained in the following way:\n\nYraw = df_cleaned['INDPRO']\nXraw = df_cleaned[['CPIAUCSL', 'TB3MS']]\n\nnum_lags  = 4  ## this is p\nnum_leads = 1  ## this is h\nX = pd.DataFrame()\n## Add the lagged values of Y\ncol = 'INDPRO'\nfor lag in range(0,num_lags+1):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{col}_lag{lag}'] = Yraw.shift(lag)\n\nfor col in Xraw.columns:\n    for lag in range(0,num_lags+1):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{col}_lag{lag}'] = Xraw[col].shift(lag)\n## Add a column on ones (for the intercept)\nX.insert(0, 'Ones', np.ones(len(X)))\n\n\n## X is now a DataFrame\nX.head()\n\n\n\n\n\n\n\n\n\nOnes\nINDPRO_lag0\nINDPRO_lag1\nINDPRO_lag2\nINDPRO_lag3\nINDPRO_lag4\nCPIAUCSL_lag0\nCPIAUCSL_lag1\nCPIAUCSL_lag2\nCPIAUCSL_lag3\nCPIAUCSL_lag4\nTB3MS_lag0\nTB3MS_lag1\nTB3MS_lag2\nTB3MS_lag3\nTB3MS_lag4\n\n\n\n\n0\n1.0\n0.014306\nNaN\nNaN\nNaN\nNaN\n-0.000690\nNaN\nNaN\nNaN\nNaN\n0.10\nNaN\nNaN\nNaN\nNaN\n\n\n1\n1.0\n0.021075\n0.014306\nNaN\nNaN\nNaN\n0.001380\n-0.000690\nNaN\nNaN\nNaN\n0.15\n0.10\nNaN\nNaN\nNaN\n\n\n2\n1.0\n0.014955\n0.021075\n0.014306\nNaN\nNaN\n0.001723\n0.001380\n-0.000690\nNaN\nNaN\n-0.11\n0.15\n0.10\nNaN\nNaN\n\n\n3\n1.0\n0.001141\n0.014955\n0.021075\n0.014306\nNaN\n0.000339\n0.001723\n0.001380\n-0.00069\nNaN\n0.37\n-0.11\n0.15\n0.10\nNaN\n\n\n4\n1.0\n-0.024240\n0.001141\n0.014955\n0.021075\n0.014306\n-0.001034\n0.000339\n0.001723\n0.00138\n-0.00069\n-0.01\n0.37\n-0.11\n0.15\n0.1\n\n\n\n\n\n\n\n\nNote that the first \\(p=\\)4 rows of X have missing values.\nThe vector \\(\\mathbf{y}\\) can be similarly created as\n\ny = Yraw.shift(-num_leads)\ny\n\n0      0.021075\n1      0.014955\n2      0.001141\n3     -0.024240\n4     -0.034465\n         ...   \n774   -0.008147\n775    0.002915\n776    0.000005\n777   -0.000951\n778         NaN\nName: INDPRO, Length: 779, dtype: float64\n\n\nThe variable y has missing values in the last h positions (it is not possible to lead the target beyond \\(T\\)).\nNotice also that we must keep the last row of X for constructing the forecast.\nNow we create two numpy arrays with the missing values stripped:\n\n## Save last row of X (converted to numpy)\nX_T = X.iloc[-1:].values\n## Subset getting only rows of X and y from p+1 to h-1\n## and convert to numpy array\ny = y.iloc[num_lags:-num_leads].values\nX = X.iloc[num_lags:-num_leads].values\n\n\nX_T\n\narray([[ 1.00000000e+00, -9.51056709e-04,  4.86991246e-06,\n         2.91450984e-03, -8.14668061e-03,  9.25729878e-04,\n         7.21400503e-04,  7.26467817e-04,  8.11330254e-04,\n        -2.79891559e-03, -1.51527417e-03, -2.00000000e-02,\n        -3.00000000e-02, -7.00000000e-02,  2.00000000e-02,\n         2.00000000e-02]])\n\n\nNow, we have to estimate the parameters and obtain the forecast.\n\n\nEstimation\nThe parameters of the model can be estimated by OLS (the OLS estimates the coefficient of the linear projection of \\(Y_{t+h}\\) on its lags and the lags of \\(X_t\\)).\nThe OLS estimator of \\(\\boldsymbol{\\beta}\\) is \\[\n\\hat{\\boldsymbol{\\beta}} = (X'X)^{-1}X'Y.\n\\]\nWhile this is the formula used to describe the OLS estimator, from a computational poijnt of view is much better to define the estimator as the solution of the set of linear equations: \\[\n(X'X)\\boldsymbol{\\beta} = X'Y\n\\]\nThe function solve can be used to solve this linear system of equation.\n\nfrom numpy.linalg import solve\n# Solving for the OLS estimator beta: (X'X)^{-1} X'Y\nbeta_ols = solve(X.T @ X, X.T @ y)\n\n## Produce the One step ahead forecast\n## % change month-to-month INDPRO\nforecast = X_T@beta_ols*100\nforecast\n\narray([0.08445815])\n\n\nThe variable forecast contains now the one-step ahead (\\(h=1\\) forecast) of INDPRO. Since INDPRO has been transformed in logarithmic differences, we are forecasting the percentage change (and multiplying by 100 gives the forecast in percentage points).\nTo obtain the \\(h\\)-step ahead forecast, we must repeat all the above steps using a different h.\n\n\nForecasting Exercise\nHow good is the forecast that the model is producing? One thing we could do to assess the forecast’s quality is to wait for the new data on industrial production and see how big the forecasting error is. However, this evaluation would not be appropriate because we need to evaluate the forecast as if it were repeatedly used to forecast future values of the target variables. To properly assess the model and its ability to forecast INDPRO, we must keep producing forecasts and calculating the errors as new data arrive. This procedure would take time as we must wait for many months to have a series of errors that is large enough.\nA different approach is to do what is called a Real-time evaluation. A Real-time evaluation procedure consists of putting ourselves in the shoes of a forecaster who has been using the forecasting model for a long time.\nIn practice, that is what are the steps to follow to do a Real-time evaluation of the model:\n\nSet \\(T\\) such that the last observation of df coincides with December 1999;\nEstimate the model using the data up to \\(T\\)\nProduce \\(\\hat{Y}_{T+1}, \\hat{Y}_{T+2}, \\dots, \\hat{Y}_{T+H}\\)\nSince we have the actual data for January, February, …, we can calculate the forecasting errors of our model \\[\n\\hat{e}_{T+h} = \\hat{Y}_{T+h} - Y_{T+h}, \\,\\, h = 1,\\ldots, H.\n\\]\nSet \\(T = T+1\\) and do all the steps above.\n\nThe process results are a series of forecasting errors we can evaluate using several metrics. The most commonly used is the MSFE, which is defined as \\[\nMSFE_h = \\frac{1}{J}\\sum_{j=1}^J  \\hat{e}_{T+j+h}^2,\n\\] where \\(J\\) is the number of errors we collected through our real-time evaluation.\nThis assignment asks you to perform a real-time evaluation assessment of our simple forecasting model and calculate the MSFE for steps \\(h=1,4,8\\).\nAs a bonus, we can evaluate different models and see how they perform differently. For instance, you might consider different numbers of lags and/or different variables in the model.\n\nHint\nA sensible way to structure the code for real-time evaluation is to use several functions. For instance, you can define a function that calculates the forecast given the DataFrame.\n\ndef calculate_forecast(df_cleaned, p = 4, H = [1,4,8], end_date = '12/1/1999',target = 'INDPRO', xvars = ['CPIAUCSL', 'TB3MS']):\n\n    ## Subset df_cleaned to use only data up to end_date\n    rt_df = df_cleaned[df_cleaned['sasdate'] &lt;= pd.Timestamp(end_date)]\n    ## Get the actual values of target at different steps ahead\n    Y_actual = []\n    for h in H:\n        os = pd.Timestamp(end_date) + pd.DateOffset(months=h)\n        Y_actual.append(df_cleaned[df_cleaned['sasdate'] == os][target]*100)\n        ## Now Y contains the true values at T+H (multiplying * 100)\n\n    Yraw = rt_df[target]\n    Xraw = rt_df[xvars]\n\n    X = pd.DataFrame()\n    ## Add the lagged values of Y\n    for lag in range(0,p):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{target}_lag{lag}'] = Yraw.shift(lag)\n\n    for col in Xraw.columns:\n        for lag in range(0,p):\n            X[f'{col}_lag{lag}'] = Xraw[col].shift(lag)\n    \n    ## Add a column on ones (for the intercept)\n    X.insert(0, 'Ones', np.ones(len(X)))\n    \n    ## Save last row of X (converted to numpy)\n    X_T = X.iloc[-1:].values\n\n    ## While the X will be the same, Y needs to be leaded differently\n    Yhat = []\n    for h in H:\n        y_h = Yraw.shift(-h)\n        ## Subset getting only rows of X and y from p+1 to h-1\n        y = y_h.iloc[p:-h].values\n        X_ = X.iloc[p:-h].values\n        # Solving for the OLS estimator beta: (X'X)^{-1} X'Y\n        beta_ols = solve(X_.T @ X_, X_.T @ y)\n        ## Produce the One step ahead forecast\n        ## % change month-to-month INDPRO\n        Yhat.append(X_T@beta_ols*100)\n\n    ## Now calculate the forecasting error and return\n\n    return np.array(Y_actual) - np.array(Yhat)\n\nWith this function, you can calculate real-time errors by looping over the end_date to ensure you end the loop at the right time.\n\nt0 = pd.Timestamp('12/1/1999')\ne = []\nT = []\nfor j in range(0, 10):\n    t0 = t0 + pd.DateOffset(months=1)\n    print(f'Using data up to {t0}')\n    ehat = calculate_forecast(df_cleaned, p = 4, H = [1,4,8], end_date = t0)\n    e.append(ehat.flatten())\n    T.append(t0)\n\n## Create a pandas DataFrame from the list\nedf = pd.DataFrame(e)\n## Calculate the RMSFE, that is, the square root of the MSFE\nnp.sqrt(edf.apply(np.square).mean())\n\nUsing data up to 2000-01-01 00:00:00\nUsing data up to 2000-02-01 00:00:00\nUsing data up to 2000-03-01 00:00:00\nUsing data up to 2000-04-01 00:00:00\nUsing data up to 2000-05-01 00:00:00\nUsing data up to 2000-06-01 00:00:00\nUsing data up to 2000-07-01 00:00:00\nUsing data up to 2000-08-01 00:00:00\nUsing data up to 2000-09-01 00:00:00\nUsing data up to 2000-10-01 00:00:00\n\n\n0    0.337110\n1    0.512690\n2    0.624035\ndtype: float64\n\n\nYou may change the function calculate_forecast to output also the actual data end the forecast, so you can, for instance, construct a plot."
  },
  {
    "objectID": "comptools_ass1.html#working-with-github",
    "href": "comptools_ass1.html#working-with-github",
    "title": "Computational Tools for Macroeconometrics",
    "section": "Working with github",
    "text": "Working with github\nThe https://github.com/uniroma/comptools-assignments repository contains four files:\n\ncomptools_ass1.qmd\nassignment1_julia.jl\nassignment1_python.py\nassignment1_r.r\n\nThe comptools_ass1.qmd is this file (in quarto format). The repository also contains the pdf and the html version of this file.\nThe other files, assignment1_julia.jl, assignment1_julia.py, and assignment1_julia.py, are the starter kit of the code you have to write in Julia, R, and Python. You can use them to start your work.\n\nUsing Visual Studio Code\nUnless you are familiar with the command line and you are using Linux or MacOS, the best way to interact with github is through Visual Studio Code. Instructions on how to install Visual Studio Code on Windows are here. For MacOS the instructions are here.\nVisual Studio Code has an extension system. The extensions extend VSCode adding features that simplify writing and interacting with code.\nThe extensions you should install are\n\nJulia Extension Instructions\nPython Extension Instruction\nR Extension Instructions\n\nThere are many other extensions that you might find useful. For those, google is your friend.\n\n\nCloning the repository\nCloning a repository from GitHub into Visual Studio Code (VSCode) allows you to work on projects directly from your local machine. Here’s a detailed step-by-step guide on how to clone the repository https://github.com/uniroma/comptools-assignments into VSCode:\n\nOpen Visual Studio Code\n\n\nStart by opening Visual Studio Code on your computer.\n\n\nAccess the Command Palette\n\n\nWith VSCode open, access the Command Palette by pressing Ctrl+Shift+P on Windows/Linux or Cmd+Shift+P on macOS. This is where you can quickly access various commands in VSCode.\n\n\nClone Repository\n\n\nIn the Command Palette, type “Git: Clone” and select the option Git: Clone from the list that appears. This action will prompt VSCode to clone a repository.\n\n\nEnter the Repository URL\n\n\nA text box asking for the repository URL will appear at the top of the VSCode window. Enter https://github.com/uniroma/comptools-assignments and press Enter. (This is the URL of the assignment 1 repository).\n\n\nChoose a Directory\n\n\nNext, VSCode will ask you to select a directory where you want to clone the repository. Navigate through your file system and choose a directory that will be the local storage place for the repository. The directory should exist. Create it if it doesn’t. Once selected, the cloning process will start.\n\n\nOpen the Cloned Repository\n\n\nAfter the repository has been successfully cloned, a notification will pop up in the bottom right corner of VSCode with the option to Open Repository. Click on it. If you missed the notification, you can navigate to the directory where you cloned the repository and open it manually from within VSCode by going to File &gt; Open Folder.\n\n\nStart Working\n\n\nNow that the repository is cloned and opened in VSCode, you can start working on the project. You can edit files, commit changes, and manage branches directly from VSCode.\n\n\n\n\n\n\n\nTip\n\n\n\n\nEnsure you have Git installed on your computer to use the Git features in VSCode. If you do not have Git installed, you can download it from the official Git website. Instructions to install Git.\nIf you are working with GitHub repositories frequently, consider authenticating with GitHub in VSCode to streamline your workflow. This can be done through the Command Palette by finding the GitHub: Sign in command.\n\n\n\n\n\nMake changes and commit them to the repository\n\nMake Your Changes\n\nOpen the repository you have cloned in VSCode.\nNavigate to the file(s) you wish to change within the VSCode Explorer pane.\nMake the necessary modifications or additions to the file(s). These changes can be anything from fixing a bug to adding new features.\n\nReview Your Changes\n\n\nAfter making changes, you can see which files have been modified by looking at the Source Control panel. You can access this panel by clicking on the Source Control icon (it looks like a branch or a fork) on the sidebar or by pressing Ctrl+Shift+G (Windows/Linux) or Cmd+Shift+G (macOS) and searching for Show control panel.\nModified files are listed within the Source Control panel. Click on a file to view the changes (differences) between your working version and the last commit. Lines added are highlighted in green, and lines removed are highlighted in red.\n\n\nStage Your Changes\n\n\nBefore committing, you need to stage your changes. Staging is like preparing and reviewing exactly what changes you will commit to without making the commit final.\nYou can stage changes by right-clicking on a modified file in the Source Control panel and selecting Stage Changes. Alternatively, you can stage all changes at once by clicking the + icon next to the “Changes” header.\n\n\nCommit Your Changes\n\n\nAfter staging your changes, commit them to the repository. To do this, type a commit message in the message box at the top of the Source Control panel. This message should briefly describe the changes you’ve made.\nPress Ctrl+Enter (Windows/Linux) or Cmd+Enter (macOS) to commit the staged changes (search for Git: Commit). Alternatively, you can click the checkmark icon (Commit) at the top of the Source Control panel.\nBefore committing, you should enter a commit message that briefly describes the changes that you have made. Commit messages are essential for making the project’s history understandable for yourself and the other collaborators.\n\n\nPush Your Changes\n\n\nIf you’re working with a remote repository (like one hosted on GitHub), you must push your commits to update the remote repository with your local changes.\nYou can push changes by clicking on the three dots (...) menu in the Source Control panel, navigating to Push and selecting it. If you’re using Git in VSCode for the first time, you might be prompted to enter your GitHub credentials or authenticate in another way.\n\n\n\n\n\n\n\nTip\n\n\n\nIt’s a good practice to pull changes from the remote repository before starting your work session (to ensure you’re working with the latest version) and before pushing your changes (to ensure no conflicts). You can pull changes by clicking on the three dots (...) menu in the Source Control panel and selecting Pull.\n\n\nThe following video explores in more detail how to use git in VSCode."
  },
  {
    "objectID": "comptools_ass1.html#footnotes",
    "href": "comptools_ass1.html#footnotes",
    "title": "Computational Tools for Macroeconometrics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTheoretically, the number of lags for the target variables and the predictors could be different. Here, we consider the simpler case in which both are equal.↩︎"
  },
  {
    "objectID": "junk/comptools_ass1.html",
    "href": "junk/comptools_ass1.html",
    "title": "Computational Tools for Macroeconometrics",
    "section": "",
    "text": "This assignment introduces students to practical and theoretical aspects of macroeconometrics, focusing on forecasting using the FRED-MD dataset. Students will learn to handle macroeconomic data, perform necessary transformations, apply univariate models to predict key economic indicators and to evaluate these forecasts."
  },
  {
    "objectID": "junk/comptools_ass1.html#introduction",
    "href": "junk/comptools_ass1.html#introduction",
    "title": "Computational Tools for Macroeconometrics",
    "section": "",
    "text": "This assignment introduces students to practical and theoretical aspects of macroeconometrics, focusing on forecasting using the FRED-MD dataset. Students will learn to handle macroeconomic data, perform necessary transformations, apply univariate models to predict key economic indicators and to evaluate these forecasts."
  },
  {
    "objectID": "junk/comptools_ass1.html#the-fred-md-dataset",
    "href": "junk/comptools_ass1.html#the-fred-md-dataset",
    "title": "Computational Tools for Macroeconometrics",
    "section": "The FRED-MD dataset",
    "text": "The FRED-MD dataset\nThe FRED-MD dataset is a comprehensive monthly database for macroeconomic research compiled by the Federal Reserve Bank of St. Louis. It features a wide array of economic indicators. The list of economic indicators can be obtained from the paper accompanying the data pdf.\nThe data can be downloaded here. The page contains all the different vintages of the data.\nLet us start to download the current.csv file:\n\nimport pandas as pd\n\n# Load the dataset\ndf = pd.read_csv('~/Downloads/current.csv')\n\n# Clean the DataFrame by removing the row with transformation codes\ndf_cleaned = df.drop(index=0)\ndf_cleaned.reset_index(drop=True, inplace=True)\ndf_cleaned['sasdate'] = pd.to_datetime(df_cleaned['sasdate'], format='%m/%d/%Y')\ndf_cleaned\n\n\n\n\n\n\n\n\n\nsasdate\nRPI\nW875RX1\nDPCERA3M086SBEA\nCMRMTSPLx\nRETAILx\nINDPRO\nIPFPNSS\nIPFINAL\nIPCONGD\n...\nDNDGRG3M086SBEA\nDSERRG3M086SBEA\nCES0600000008\nCES2000000008\nCES3000000008\nUMCSENTx\nDTCOLNVHFNM\nDTCTHFNM\nINVEST\nVIXCLSx\n\n\n\n\n0\n1959-01-01\n2583.560\n2426.0\n15.188\n2.766768e+05\n18235.77392\n21.9665\n23.3891\n22.2688\n31.7011\n...\n18.294\n10.152\n2.13\n2.45\n2.04\nNaN\n6476.00\n12298.00\n84.2043\nNaN\n\n\n1\n1959-02-01\n2593.596\n2434.8\n15.346\n2.787140e+05\n18369.56308\n22.3966\n23.7048\n22.4617\n31.9337\n...\n18.302\n10.167\n2.14\n2.46\n2.05\nNaN\n6476.00\n12298.00\n83.5280\nNaN\n\n\n2\n1959-03-01\n2610.396\n2452.7\n15.491\n2.777753e+05\n18523.05762\n22.7193\n23.8483\n22.5719\n31.9337\n...\n18.289\n10.185\n2.15\n2.45\n2.07\nNaN\n6508.00\n12349.00\n81.6405\nNaN\n\n\n3\n1959-04-01\n2627.446\n2470.0\n15.435\n2.833627e+05\n18534.46600\n23.2032\n24.1927\n22.9026\n32.4374\n...\n18.300\n10.221\n2.16\n2.47\n2.08\nNaN\n6620.00\n12484.00\n81.8099\nNaN\n\n\n4\n1959-05-01\n2642.720\n2486.4\n15.622\n2.853072e+05\n18679.66354\n23.5528\n24.3936\n23.1231\n32.5925\n...\n18.280\n10.238\n2.17\n2.48\n2.08\n95.3\n6753.00\n12646.00\n80.7315\nNaN\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n776\n2023-09-01\n19111.748\n15741.9\n116.594\n1.507530e+06\n705304.00000\n103.2096\n101.0935\n101.3665\n102.1034\n...\n120.395\n123.976\n29.90\n34.55\n26.62\n67.9\n508808.61\n913938.95\n5074.6108\n15.0424\n\n\n777\n2023-10-01\n19145.402\n15784.6\n116.663\n1.505477e+06\n703528.00000\n102.3722\n100.5292\n100.5527\n101.1664\n...\n120.040\n124.228\n29.97\n34.67\n26.65\n63.8\n513229.64\n918210.64\n5015.5456\n19.0462\n\n\n778\n2023-11-01\n19213.108\n15859.9\n117.127\n1.514733e+06\n703336.00000\n102.6710\n100.9362\n101.2159\n101.8557\n...\n119.325\n124.551\n30.26\n34.96\n26.89\n61.3\n517434.30\n922552.40\n4999.7208\n13.8563\n\n\n779\n2023-12-01\n19251.946\n15899.0\n117.773\n1.530296e+06\n706180.00000\n102.6715\n100.8332\n101.2843\n101.9884\n...\n119.193\n124.917\n30.45\n35.01\n27.14\n69.7\n522366.13\n928336.14\n5077.4222\n12.6960\n\n\n780\n2024-01-01\n19377.558\n15948.8\n117.639\nNaN\n700291.00000\n102.5739\n100.9984\n101.7258\n102.6235\n...\n118.745\n125.662\n30.56\n35.21\n27.22\nNaN\nNaN\nNaN\n5105.3504\n13.3453\n\n\n\n\n781 rows × 128 columns\n\n\n\n\n\n# Extract transformation codes\ntransformation_codes = df.iloc[0, 1:].to_frame().reset_index()\ntransformation_codes.columns = ['Series', 'Transformation_Code']\n\nThe transformation codes map variables to the transformations we must apply to each variable to render them (approximately) stationary. The data frame transformation_codes has the variable’s name (Series) and its transformation (Transformation_Code). There are six possible transformations (\\(x_t\\) denotes the variable to which the transformation is to be applied):\n\ntransformation_code=1: no trasformation\ntransformation_code=2: \\(\\Delta x_t\\)\ntransformation_code=3: \\(\\Delta^2 x_t\\)\ntransformation_code=4: \\(log(x_t)\\)\ntransformation_code=5: \\(\\Delta log(x_t)\\)\ntransformation_code=6: \\(\\Delta^2 log(x_t)\\)\ntransformation_code=7: \\(\\Delta (x_t/x_{t-1} - 1)\\)\n\nWe can apply these transformations using the following code:\n\nimport numpy as np\n\n# Function to apply transformations based on the transformation code\ndef apply_transformation(series, code):\n    if code == 1:\n        # No transformation\n        return series\n    elif code == 2:\n        # First difference\n        return series.diff()\n    elif code == 3:\n        # Second difference\n        return series.diff().diff()\n    elif code == 4:\n        # Log\n        return np.log(series)\n    elif code == 5:\n        # First difference of log\n        return np.log(series).diff()\n    elif code == 6:\n        # Second difference of log\n        return np.log(series).diff().diff()\n    elif code == 7:\n        # Delta (x_t/x_{t-1} - 1)\n        return series.pct_change()\n    else:\n        raise ValueError(\"Invalid transformation code\")\n\n# Applying the transformations to each column in df_cleaned based on transformation_codes\nfor series_name, code in transformation_codes.values:\n    df_cleaned[series_name] = apply_transformation(df_cleaned[series_name].astype(float), float(code))\n\n\n1df_cleaned = df_cleaned[2:]\n2df_cleaned.reset_index(drop=True, inplace=True)\ndf_cleaned.head()\n\n\n1\n\nSince some transformations induce missing values, we drop the first two observations of the dataset\n\n2\n\nWe reset the index so that the first observation of the dataset has index 0\n\n\n\n\n\n\n\n\n\n\n\n\nsasdate\nRPI\nW875RX1\nDPCERA3M086SBEA\nCMRMTSPLx\nRETAILx\nINDPRO\nIPFPNSS\nIPFINAL\nIPCONGD\n...\nDNDGRG3M086SBEA\nDSERRG3M086SBEA\nCES0600000008\nCES2000000008\nCES3000000008\nUMCSENTx\nDTCOLNVHFNM\nDTCTHFNM\nINVEST\nVIXCLSx\n\n\n\n\n0\n1959-03-01\n0.006457\n0.007325\n0.009404\n-0.003374\n0.008321\n0.014306\n0.006035\n0.004894\n0.000000\n...\n-0.001148\n0.000292\n-0.000022\n-0.008147\n0.004819\nNaN\n0.004929\n0.004138\n-0.014792\nNaN\n\n\n1\n1959-04-01\n0.006510\n0.007029\n-0.003622\n0.019915\n0.000616\n0.021075\n0.014338\n0.014545\n0.015650\n...\n0.001312\n0.001760\n-0.000022\n0.012203\n-0.004890\nNaN\n0.012134\n0.006734\n0.024929\nNaN\n\n\n2\n1959-05-01\n0.005796\n0.006618\n0.012043\n0.006839\n0.007803\n0.014955\n0.008270\n0.009582\n0.004770\n...\n-0.001695\n-0.001867\n-0.000021\n-0.004090\n-0.004819\nNaN\n0.002828\n0.002020\n-0.015342\nNaN\n\n\n3\n1959-06-01\n0.003068\n0.003012\n0.003642\n-0.000097\n0.009064\n0.001141\n0.007034\n0.007128\n-0.004767\n...\n0.003334\n0.001946\n-0.004619\n0.003992\n0.004796\nNaN\n0.009726\n0.009007\n-0.012252\nNaN\n\n\n4\n1959-07-01\n-0.000580\n-0.000762\n-0.003386\n0.012155\n-0.000330\n-0.024240\n0.001168\n0.008249\n0.013054\n...\n-0.001204\n-0.000013\n0.000000\n-0.004040\n-0.004796\nNaN\n-0.004631\n-0.001000\n0.029341\nNaN\n\n\n\n\n5 rows × 128 columns\n\n\n\n\n\n1import matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\n\n2series_to_plot = ['INDPRO', 'CPIAUCSL', 'TB3MS']\nseries_names = ['Industrial Production',\n                'Inflation (CPI)',\n                '3-month Treasury Bill rate']\n\n\n# Create a figure and a grid of subplots\n3fig, axs = plt.subplots(len(series_to_plot), 1, figsize=(8, 15))\n\n# Iterate over the selected series and plot each one\nfor ax, series_name, plot_title in zip(axs, series_to_plot, series_names):\n4    if series_name in df_cleaned.columns:\n5        dates = pd.to_datetime(df_cleaned['sasdate'], format='%m/%d/%Y')\n6        ax.plot(dates, df_cleaned[series_name], label=plot_title)\n7        ax.xaxis.set_major_locator(mdates.YearLocator(base=5))\n        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n8        ax.set_title(plot_title)\n9        ax.set_xlabel('Year')\n        ax.set_ylabel('Transformed Value')\n10        ax.legend(loc='upper left')\n11        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')\n    else:\n        ax.set_visible(False)  # Hide plots for which the data is not available\n\n12plt.tight_layout()\n13plt.show()\n\n\n1\n\nWe use library matplotlib to plot\n\n2\n\nWe consider three series (INDPRO, CPIAUCSL, TB3MS) and assign them human-readable names (“Industrial Production”, “Inflation (CPI)”, “3-month Treasury Bill rate.”).\n\n3\n\nWe create a figure with three (len(series_to_plot)) subplots arranged vertically. The figure size is 8x15 inches.\n\n4\n\nWe check if the series exists in each series df_cleaned DataFrame columns.\n\n5\n\nWe convert the sasdate column to datetime format (not necessary, since sasdate was converter earlier)\n\n6\n\nWe plot each series against the sasdate on the corresponding subplot, labeling the plot with its human-readable name.\n\n7\n\nWe format the x-axis to display ticks and label the x-axis with dates taken every five years.\n\n8\n\nEach subplot is titled with the name of the economic indicator.\n\n9\n\nWe label the x-axis “Year,” and the y-axis “Transformed Value,” to indicate that the data was transformed before plotting.\n\n10\n\nA legend is added to the upper left of each subplot for clarity.\n\n11\n\nWe rotate the x-axis labels by 45 degrees to prevent overlap and improve legibility.\n\n12\n\nplt.tight_layout() automatically adjusts subplot parameters to give specified padding and avoid overlap.\n\n13\n\nplt.show() displays the figure with its subplots."
  },
  {
    "objectID": "junk/comptools_ass1.html#forecasting-in-time-series",
    "href": "junk/comptools_ass1.html#forecasting-in-time-series",
    "title": "Computational Tools for Macroeconometrics",
    "section": "Forecasting in Time Series",
    "text": "Forecasting in Time Series\nForecasting in time series analysis involves using historical data to predict future values. The objective is to model the conditional expectation of a time series based on past observations.\n\nDirect Forecasts\nDirect forecasting involves modeling the target variable directly at the desired forecast horizon. Unlike iterative approaches, which forecast one step ahead and then use those forecasts as inputs for subsequent steps, direct forecasting directly models the relationship between past observations and future value.\n\n\nARX Models\nAutoregressive Moving with predictors (ARX) models are a class of univariate time series models that extend ARMA models by incorporating exogenous (independent) variables. These models are formulated as follows:\n\\[\n\\begin{aligned}\nY_{t+h} &=  \\alpha + \\phi_0 Y_t + \\phi_1 Y_{t-1} + \\dots + \\phi_p Y_{t-p} + \\theta_{0,1} X_{t,1} + \\theta_{1,1} X_{t-1,1} + \\dots + \\theta_{p,1} X_{t-p,1} + \\dots + \\theta_{0,k} X_{t,k} + \\dots + \\theta_{p,k} X_{t-p,k} + u_{t+h}\\\\\n        &=  \\alpha + \\sum_{i=0}^p \\phi_i Y_{t-i} + \\sum_{j=1}^k\\sum_{s=0}^p \\theta_{s,j} X_{t-s,j} + \\epsilon_{t+h}\n\\end{aligned}\n\\tag{1}\\]\n\n\\(Y_{t+h}\\): The target variable at time \\(t+h\\).\n\\(X_{t,j}\\): Predictors (variable \\(j=1,\\ldots,k\\) at time \\(t\\)).\n\\(p\\) number of lags of the target and the predictors.1\n\\(\\phi_i\\), \\(i=0,\\dots,p\\), and \\(\\theta_{j,s}\\), \\(j=1,\\dots,k\\), \\(s=1,\\ldots,r\\): Parameters of the model.\n\\(\\epsilon_{t+h}\\): error term.\n\nFor instance, to predict Industrial Prediction using as predictor inflation and the 3-month t-bill, the target variable is INDPRO, and the predictors are CPIAUSL and TB3MS. Notice that the target and the predictors are the transformed variables. Thus, if we use INDPRO as the target, we are predicting the log-difference of industrial production, which is a good approximation for its month-to-month percentage change.\nBy convention, the data ranges from \\(t=1,\\ldots,T\\), where \\(T\\) is the last period, we have data (for the df_cleaned dataset, \\(T\\) corresponds to January 2024).\n\n\nForecasting with ARX\nSuppose that we know the parameters of the model for the moment. To obtain a forecast for \\(Y_{T+h}\\), the \\(h\\)-step ahead forecast, we calculate \\[\n\\begin{aligned}\n\\hat{Y}_{T+h} &=  \\alpha + \\phi_0 Y_T + \\phi_1 Y_{T-1} + \\dots + \\phi_p Y_{T-p} \\\\\n                  &\\,\\,\\quad \\quad + \\theta_{0,1} X_{T,1} + \\theta_{1,1} X_{T-1,1} + \\dots + \\theta_{p,1} X_{T-p,1} \\\\\n                  &\\,\\,\\quad \\quad + \\dots + \\theta_{0,k} X_{T,k} + \\dots + \\theta_{p,k} X_{T-p,k}\\\\\n        &=  \\alpha + \\sum_{i=0}^p \\phi_i Y_{T-i} + \\sum_{j=1}^k\\sum_{s=0}^p \\theta_{s,j} X_{T-s,j}\n\\end{aligned}\n\\]\nWhile this is conceptually easy, implementing the steps needed to calculate the forecast is insidious, and care must be taken to ensure we are calculating the correct forecast.\nTo start, it is convenient to rewrite the model in Equation 1 as a linear model \\[\n\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{u},\n\\] where \\(\\boldsymbol{\\beta}\\) is the vector (of size \\(1+(1+p)(1+k)\\)) \\[\n\\boldsymbol{\\beta}=\\begin{pmatrix}\\alpha\\\\\n\\phi_{0}\\\\\n\\vdots\\\\\n\\phi_{p}\\\\\n\\theta_{0,1}\\\\\n\\vdots\\\\\n\\theta_{p,1}\\\\\n\\vdots\\\\\n\\theta_{1,k}\\\\\n\\vdots\\\\\n\\theta_{p,k}\n\\end{pmatrix},\n\\] \\(\\mathbf{y}\\) and \\(\\mathbf{X}\\) are respectively given by \\[\n\\mathbf{y} = \\begin{pmatrix}\ny_{p+h+1}  \\\\\ny_{p+h+2}\\\\\n\\vdots \\\\\ny_{T}\n\\end{pmatrix}\n\\] and \\[\n\\mathbf{X} = \\begin{pmatrix}1 & Y_{p+1} & Y_{p} & \\cdots & Y_{1} & X_{p+1,1} & X_{p,1} & \\cdots & X_{1,1} & X_{p+1,k} & X_{p,k} & \\cdots & X_{1,k}\\\\\n\\vdots & \\vdots & \\vdots &  & \\vdots & \\vdots & \\vdots &  & \\vdots & \\vdots & \\vdots &  & \\vdots\\\\\n1 & Y_{T-h-1} & Y_{T-h-2} & \\cdots & Y_{T-h-p-1} & X_{T-h-1,1} & X_{T-h-2,1} & \\cdots & X_{T-h-p-1,1} & X_{T-h-1,k} & X_{T-h-2,k} & \\cdots & X_{T-h-p-1,k}\\\\\n1 & Y_{T-h} & Y_{T-h-1} & \\cdots & Y_{T-h-p} & X_{T-h,1} & X_{T-h-1,1} & \\cdots & X_{T-h-p,1} & X_{T-h,k} & X_{T-h-1,k} &  & X_{T-h-p,k}\n\\end{pmatrix}.\n\\] The size of \\(\\mathbf{X}\\) is \\((T-p-h)\\times 1+(1+k)(1+p)\\) and that of \\(\\mathbf{y}\\) is \\(T-h-p\\).\nThe matrix \\(\\mathbf{X}\\) can be obtained in the following way:\n\nYraw = df_cleaned['INDPRO']\nXraw = df_cleaned[['CPIAUCSL', 'TB3MS']]\n\nnum_lags  = 4  ## this is p\nnum_leads = 1  ## this is h\nX = pd.DataFrame()\n## Add the lagged values of Y\ncol = 'INDPRO'\nfor lag in range(0,num_lags):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{col}_lag{lag}'] = Yraw.shift(lag)\n\nfor col in Xraw.columns:\n    for lag in range(0,num_lags):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{col}_lag{lag}'] = Xraw[col].shift(lag)\n## Add a column on ones (for the intercept)\nX.insert(0, 'Ones', np.ones(len(X)))\n\n\n## X is now a DataFrame\nX.head()\n\n\n\n\n\n\n\n\n\nOnes\nINDPRO_lag0\nINDPRO_lag1\nINDPRO_lag2\nINDPRO_lag3\nCPIAUCSL_lag0\nCPIAUCSL_lag1\nCPIAUCSL_lag2\nCPIAUCSL_lag3\nTB3MS_lag0\nTB3MS_lag1\nTB3MS_lag2\nTB3MS_lag3\n\n\n\n\n0\n1.0\n0.014306\nNaN\nNaN\nNaN\n-0.000690\nNaN\nNaN\nNaN\n0.10\nNaN\nNaN\nNaN\n\n\n1\n1.0\n0.021075\n0.014306\nNaN\nNaN\n0.001380\n-0.000690\nNaN\nNaN\n0.15\n0.10\nNaN\nNaN\n\n\n2\n1.0\n0.014955\n0.021075\n0.014306\nNaN\n0.001723\n0.001380\n-0.000690\nNaN\n-0.11\n0.15\n0.10\nNaN\n\n\n3\n1.0\n0.001141\n0.014955\n0.021075\n0.014306\n0.000339\n0.001723\n0.001380\n-0.00069\n0.37\n-0.11\n0.15\n0.10\n\n\n4\n1.0\n-0.024240\n0.001141\n0.014955\n0.021075\n-0.001034\n0.000339\n0.001723\n0.00138\n-0.01\n0.37\n-0.11\n0.15\n\n\n\n\n\n\n\n\nNote that the first \\(p=\\)4 rows of X have missing values.\nThe vector \\(\\mathbf{y}\\) can be similarly created as\n\ny = Yraw.shift(-num_leads)\ny\n\n0      0.021075\n1      0.014955\n2      0.001141\n3     -0.024240\n4     -0.034465\n         ...   \n774   -0.008147\n775    0.002915\n776    0.000005\n777   -0.000951\n778         NaN\nName: INDPRO, Length: 779, dtype: float64\n\n\nThe variable y has missing values in the last h positions (it is not possible to lead the target beyond \\(T\\)).\nNotice also that we must keep the last row of X for constructing the forecast.\nNow we create two numpy arrays with the missing values stripped:\n\n## Save last row of X (converted to numpy)\nX_T = X.iloc[-1:].values\n## Subset getting only rows of X and y from p+1 to h-1\n## and convert to numpy array\ny = y.iloc[num_lags:-num_leads].values\nX = X.iloc[num_lags:-num_leads].values\n\nNow, we have to estimate the parameters and obtain the forecast.\n\n\nEstimation\nThe parameters of the model can be estimated by OLS (the OLS estimates the coefficient of the linear projection of \\(Y_{t+h}\\) on its lags and the lags of \\(X_t\\)).\nThe OLS estimator of \\(\\boldsymbol{\\beta}\\) is \\[\n\\hat{\\boldsymbol{\\beta}} = (X'X)^{-1}X'Y.\n\\]\nWhile this is the formula used to describe the OLS estimator, from a computational poijnt of view is much better to define the estimator as the solution of the set of linear equations: \\[\n(X'X)\\boldsymbol{\\beta} = X'Y\n\\]\nThe function solve can be used to solve this linear system of equation.\n\nfrom numpy.linalg import solve\n# Solving for the OLS estimator beta: (X'X)^{-1} X'Y\nbeta_ols = solve(X.T @ X, X.T @ y)\n\n## Produce the One step ahead forecast\n## % change month-to-month INDPRO\nforecast = X_T@beta_ols*100\n\nThe variable forecast contains now the one-step ahead (\\(h=1\\) forecast) of INDPRO. Since INDPRO has been transformed in logarithmic differences, we are forecasting the percentage change (and multiplying by 100 gives the forecast in percentage points).\nTo obtain the \\(h\\)-step ahead forecast, we must repeat all the above steps using a different h.\n\n\nForecasting Exercise\nHow good is the forecast that the model is producing? One thing we could do to assess the forecast’s quality is to wait for the new data on industrial production and see how big the forecasting error is. However, this evaluation would not be appropriate because we need to evaluate the forecast as if it were repeatedly used to forecast future values of the target variables. To properly assess the model and its ability to forecast INDPRO, we must keep producing forecasts and calculating the errors as new data arrive. This procedure would take time as we must wait for many months to have a series of errors that is large enough.\nA different approach is to do what is called a Real-time evaluation. A Real-time evaluation procedure consists of putting ourselves in the shoes of a forecaster who has been using the forecasting model for a long time.\nIn practice, that is what are the steps to follow to do a Real-time evaluation of the model:\n\nSet \\(T\\) such that the last observation of df coincides with December 1999;\nEstimate the model using the data up to \\(T\\)\nProduce \\(\\hat{Y}_{T+1}, \\hat{Y}_{T+2}, \\dots, \\hat{Y}_{T+H}\\)\nSince we have the actual data for January, February, …, we can calculate the forecasting errors of our model \\[\n\\hat{e}_{T+h} = \\hat{Y}_{T+h} - Y_{T+h}, \\,\\, h = 1,\\ldots, H.\n\\]\nSet \\(T = T+1\\) and do all the steps above.\n\nThe process results are a series of forecasting errors we can evaluate using several metrics. The most commonly used is the MSFE, which is defined as \\[\nMSFE_h = \\frac{1}{J}\\sum_{j=1}^J  \\hat{e}_{T+j+h}^2,\n\\] where \\(J\\) is the number of errors we collected through our real-time evaluation.\nThis assignment asks you to perform a real-time evaluation assessment of our simple forecasting model and calculate the MSFE for steps \\(h=1,4,8\\).\nAs a bonus, we can evaluate different models and see how they perform differently. For instance, you might consider different numbers of lags and/or different variables in the model.\n\nHint\nA sensible way to structure the code for real-time evaluation is to use several functions. For instance, you can define a function that calculates the forecast given the DataFrame.\n\ndef calculate_forecast(df_cleaned, p = 4, H = [1,4,8], end_date = '12/1/1999',target = 'INDPRO', xvars = ['CPIAUCSL', 'TB3MS']):\n\n    ## Subset df_cleaned to use only data up to end_date\n    rt_df = df_cleaned[df_cleaned['sasdate'] &lt;= pd.Timestamp(end_date)]\n    ## Get the actual values of target at different steps ahead\n    Y_actual = []\n    for h in H:\n        os = pd.Timestamp(end_date) + pd.DateOffset(months=h)\n        Y_actual.append(df_cleaned[df_cleaned['sasdate'] == os][target]*100)\n        ## Now Y contains the true values at T+H (multiplying * 100)\n\n    Yraw = rt_df[target]\n    Xraw = rt_df[xvars]\n\n    X = pd.DataFrame()\n    ## Add the lagged values of Y\n    for lag in range(0,p):\n        # Shift each column in the DataFrame and name it with a lag suffix\n        X[f'{target}_lag{lag}'] = Yraw.shift(lag)\n\n    for col in Xraw.columns:\n        for lag in range(0,p):\n            X[f'{col}_lag{lag}'] = Xraw[col].shift(lag)\n    \n    ## Add a column on ones (for the intercept)\n    X.insert(0, 'Ones', np.ones(len(X)))\n    \n    ## Save last row of X (converted to numpy)\n    X_T = X.iloc[-1:].values\n\n    ## While the X will be the same, Y needs to be leaded differently\n    Yhat = []\n    for h in H:\n        y_h = Yraw.shift(-h)\n        ## Subset getting only rows of X and y from p+1 to h-1\n        y = y_h.iloc[p:-h].values\n        X_ = X.iloc[p:-h].values\n        # Solving for the OLS estimator beta: (X'X)^{-1} X'Y\n        beta_ols = solve(X_.T @ X_, X_.T @ y)\n        ## Produce the One step ahead forecast\n        ## % change month-to-month INDPRO\n        Yhat.append(X_T@beta_ols*100)\n\n    ## Now calculate the forecasting error and return\n\n    return np.array(Y_actual) - np.array(Yhat)\n\nWith this function, you can calculate real-time errors by looping over the end_date to ensure you end the loop at the right time.\n\nt0 = pd.Timestamp('12/1/1999')\ne = []\nT = []\nfor j in range(0, 10):\n    t0 = t0 + pd.DateOffset(months=1)\n    print(f'Using data up to {t0}')\n    ehat = calculate_forecast(df_cleaned, p = 4, H = [1,4,8], end_date = t0)\n    e.append(ehat.flatten())\n    T.append(t0)\n\n## Create a pandas DataFrame from the list\nedf = pd.DataFrame(e)\n## Calculate the RMSFE, that is, the square root of the MSFE\nnp.sqrt(edf.apply(np.square).mean())\n\nUsing data up to 2000-01-01 00:00:00\nUsing data up to 2000-02-01 00:00:00\nUsing data up to 2000-03-01 00:00:00\nUsing data up to 2000-04-01 00:00:00\nUsing data up to 2000-05-01 00:00:00\nUsing data up to 2000-06-01 00:00:00\nUsing data up to 2000-07-01 00:00:00\nUsing data up to 2000-08-01 00:00:00\nUsing data up to 2000-09-01 00:00:00\nUsing data up to 2000-10-01 00:00:00\n\n\n0    0.337110\n1    0.512690\n2    0.624035\ndtype: float64\n\n\nYou may change the function calculate_forecast to output also the actual data end the forecast, so you can, for instance, construct a plot."
  },
  {
    "objectID": "junk/comptools_ass1.html#footnotes",
    "href": "junk/comptools_ass1.html#footnotes",
    "title": "Computational Tools for Macroeconometrics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTheoretically, the number of lags for the target variables and the predictors could be different. Here, we consider the simpler case in which both are equal.↩︎"
  }
]